{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuBCRwd85WYjvnCVUk2ojM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewu2023/CS589-HW4/blob/main/CS589_NeuralNets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "Dg570F-XxICR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEWGG2M_xNfo",
        "outputId": "93085b2f-4c0b-4539-d364-d8d4fc9615e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "7B-JBg83M1ok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsRlxN3fLmfw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Neural Network Class"
      ],
      "metadata": {
        "id": "nOW3NjBRNpsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add a debug flag to show intermediate computation steps\n",
        "class NeuralNetwork():\n",
        "    def __init__(self, networkShape, trainData: pd.DataFrame, classSet, weights=None, regParam=0, debugFlag=False):\n",
        "        \"\"\"\n",
        "        Constructor for the neural network class.\n",
        "        \n",
        "        networkShape: A list of integers that contains the number of neurons to use in each layer\n",
        "\n",
        "        trainData: The data set that will be used to train the model\n",
        "\n",
        "        weights: A list of weight matrices for each hidden layer. If initialized to None, the constructor will assign random weights\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Process training data\n",
        "        \"\"\"\n",
        "        self.trainData = trainData\n",
        "\n",
        "        \n",
        "        # Get a copy of the training data without the labels\n",
        "        self.noLabelTrainData = trainData.loc[:, trainData.columns!='class']\n",
        "\n",
        "        # Encode class vectors\n",
        "        self.classVectors = {}\n",
        "        for i in range(len(trainData)):\n",
        "            # Get current row from training data\n",
        "            row = trainData.iloc[i]\n",
        "\n",
        "            # Get current class\n",
        "            rowClass = row['class']\n",
        "\n",
        "            # Create class vector (Need to format class labels as numbers)\n",
        "            classVector = np.zeros(shape=(1, len(classSet)))\n",
        "            classVector[rowClass - 1] = 1\n",
        "\n",
        "            self.classVectors[i] = classVector \n",
        "\n",
        "        self.networkShape = networkShape\n",
        "\n",
        "        # Set the value of the regularization parameter\n",
        "        self.regParam = regParam\n",
        "\n",
        "        # Set debug flag to show output of intermediate computations\n",
        "        self.debugFlag = debugFlag\n",
        "\n",
        "        # Instance variable storing weight matrices\n",
        "        self.layers = []\n",
        "        \n",
        "        # Initialize layers\n",
        "        for i in range(len(networkShape) - 1):\n",
        "            # Get the number of neurons in the current and next layers\n",
        "            numCurLayer = networkShape[i] + 1 # Account for neurons + bias term in current layer\n",
        "            numNextLayer = networkShape[i + 1]\n",
        "\n",
        "            # Initialize matrix for the current layer\n",
        "            # Number of rows = number of neurons in layer i + 1\n",
        "            # Number of columns = number of neurons in layer i\n",
        "            layerMatrix = np.zeros(shape=(numNextLayer, numCurLayer))\n",
        "            if weights:\n",
        "                layerMatrix = weights[i]\n",
        "            else:\n",
        "                self._init_matrix(layerMatrix)\n",
        "            \n",
        "            # Append current layer to the list of layers\n",
        "            self.layers.append(layerMatrix)\n",
        "        \n",
        "    def _init_matrix(self, matrix: np.ndarray):\n",
        "        rows, cols = matrix.shape\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                matrix[i, j] = norm.rvs()\n",
        "    \n",
        "    # Definition for the sigmoid function\n",
        "    def sigmoid(self, x):\n",
        "        return (1 / (1 + np.exp(-x)))\n",
        "    \n",
        "    # Compute activation vector\n",
        "    def compute_activation_vector(self, weightedSums: np.ndarray):\n",
        "        numRows, numCols = weightedSums.shape\n",
        "        activationVector = np.zeros(shape=(numRows, numCols))\n",
        "\n",
        "        for i in range(numRows):\n",
        "            # Get weighted sum from i-th row\n",
        "            x = weightedSums[i, 0]\n",
        "\n",
        "            # Compute output of sigmoid function and place it in activation vector\n",
        "            activationVector[i, 0] = self.sigmoid(x)\n",
        "        \n",
        "        return activationVector\n",
        "    \n",
        "    # Method for propagating forward one instance\n",
        "    def propagate_one(self, instance):\n",
        "        # Add a bias term to the instance\n",
        "        instanceAsNP = instance.to_numpy()\n",
        "        instanceVector = np.concatenate(([1], instanceAsNP))\n",
        "        \n",
        "        # Make instance vector a column vector\n",
        "        instanceVector = np.atleast_2d(instanceVector).T\n",
        "        \n",
        "        # Iterate over each layer and compute activations for each neuron\n",
        "        prevActivation = instanceVector # Keep track of the activation vector for previous layer\n",
        "\n",
        "        # If the debug flag was set, print out the first instance vector\n",
        "        if self.debugFlag:\n",
        "            print(f\"Value of a0:\\n{prevActivation}\\n\")\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            # Get current weight matrix\n",
        "            curTheta = self.layers[i]\n",
        "\n",
        "            # Compute weighted sum vector (z-matrix): Theta^{l=i-1} * a^{l=i-1}\n",
        "            z = np.matmul(curTheta, prevActivation)\n",
        "\n",
        "            # Compute activation vector of current layer\n",
        "            curActivationVec = self.compute_activation_vector(z)\n",
        "            \n",
        "            # Add bias term to current activation vector\n",
        "            curActivationVec = np.concatenate(([[1]], curActivationVec)) # Prepend 1 to vector\n",
        "\n",
        "            # Update previous activation vector\n",
        "            prevActivation = curActivationVec\n",
        "\n",
        "            # Print results of computation at this step if debug flag is on\n",
        "            if self.debugFlag:\n",
        "                print(f\"Value of z{i + 1}:\\n{z}\")\n",
        "                print(f\"Value of a{i + 1}:\\n{curActivationVec}\\n\")\n",
        "        \n",
        "        # Compute activation at the final layer\n",
        "        lastTheta = self.layers[len(self.layers) - 1]\n",
        "        lastZMat = np.matmul(lastTheta, prevActivation)\n",
        "        outputVector = self.compute_activation_vector(lastZMat)\n",
        "\n",
        "        # If the debug flag was set, print results of this final computation\n",
        "        if self.debugFlag:\n",
        "            print(f\"Value of z{len(self.layers)}:\\n{lastZMat}\")\n",
        "            print(f\"Value of a{len(self.layers)}:\\n{outputVector}\\n\")\n",
        "\n",
        "        # Return as a vector in the event there are multiple outputs\n",
        "        return outputVector\n",
        "\n",
        "    # Compute error for an individual output of the neural network\n",
        "    def compute_one_instance_err(self, expVal, predVal):\n",
        "        return -expVal * np.log(predVal) - (1 - expVal) * np.log(1 - predVal)\n",
        "\n",
        "    # Helper method for computing regularized error\n",
        "    def compute_error(self):\n",
        "        # Keep track of total error across all training instances\n",
        "        totalErr = 0\n",
        "\n",
        "        # Iterate over all training instances\n",
        "        for i in range(len(self.noLabelTrainData)):\n",
        "            # Get current instance and perform forward propagation on it\n",
        "            curInstance = self.noLabelTrainData.iloc[i]\n",
        "            predVector = self.propagate_one(curInstance) # Will be a vector\n",
        "\n",
        "            # Get expected value for current instance\n",
        "            expVal = (self.trainData.iloc[i]['class'])\n",
        "\n",
        "            # Build expected values vector\n",
        "            # Vector takes the form of [0, 0, ..., expVal, 0, ..., 0]\n",
        "            # Number of output neurons = number of classes\n",
        "            numNeurons = self.networkShape[len(self.networkShape) - 1]\n",
        "            expVector = np.zeros(shape=(numNeurons, 1))\n",
        "            \n",
        "            # How to determine where to place 0s and where to place the expected value?\n",
        "            expVector[0, 0] = expVal\n",
        "\n",
        "            # Compute error vector\n",
        "            vectorizedErrorFunc = np.vectorize(self.compute_one_instance_err)\n",
        "            errVector = vectorizedErrorFunc(expVector, predVector)\n",
        "\n",
        "            # Sum all elements of error vector, then add it to total error\n",
        "            totalErr += np.sum(errVector)\n",
        "        \n",
        "        # Compute average error\n",
        "        avgErr = totalErr / len(self.trainData)\n",
        "\n",
        "        \"\"\" Compute the squared sum of all weights in the network \"\"\"\n",
        "        weightSqSum = 0\n",
        "        for weightMatrix in self.layers:\n",
        "            # Square all of the weights\n",
        "            squaredMatrix = np.multiply(weightMatrix, weightMatrix)\n",
        "\n",
        "            # Add all columns, then add each column's total to get the total sum for this matrix\n",
        "            colSums = np.sum(squaredMatrix, axis=0)\n",
        "            matrixTotal = np.sum(colSums)\n",
        "\n",
        "            # Add matrix total to sum of the weights squared\n",
        "            weightSqSum += matrixTotal\n",
        "        \n",
        "        # Regularize error\n",
        "        weightSqSum *= (self.regParam / (2 * len(self.trainData)))\n",
        "\n",
        "        # Return error + regularization term\n",
        "        return avgErr + weightSqSum"
      ],
      "metadata": {
        "id": "PlC7io6JNYw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Neural Net"
      ],
      "metadata": {
        "id": "kxzyGtabHfub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {\n",
        "    'x': [0.13000, 0.42000], \n",
        "    'class': [0.90000, 0.23000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data=d)\n",
        "df_noLabels = df.loc[:, df.columns!='class']\n",
        "\n",
        "networkShape = [1, 2, 1]\n",
        "weights = [\n",
        "    np.array(\n",
        "        [[0.40000, 0.10000],\n",
        "         [0.30000, 0.20000]],\n",
        "    ),\n",
        "\n",
        "    np.array([[0.70000, 0.50000, 0.60000]])\n",
        "]\n",
        "\n",
        "network = NeuralNetwork(networkShape, trainData=df, weights=weights, debugFlag=True)\n",
        "print(network.compute_error())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_y6PpYnHiGr",
        "outputId": "a41d4111-3188-4471-f87a-a6c117c15f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of a0:\n",
            "[[1.  ]\n",
            " [0.13]]\n",
            "\n",
            "Value of z1:\n",
            "[[0.413]\n",
            " [0.326]]\n",
            "Value of a1:\n",
            "[[1.       ]\n",
            " [0.601807 ]\n",
            " [0.5807858]]\n",
            "\n",
            "Value of z2:\n",
            "[[1.34937498]]\n",
            "Value of a2:\n",
            "[[0.79402743]]\n",
            "\n",
            "Value of a0:\n",
            "[[1.  ]\n",
            " [0.42]]\n",
            "\n",
            "Value of z1:\n",
            "[[0.442]\n",
            " [0.384]]\n",
            "Value of a1:\n",
            "[[1.        ]\n",
            " [0.60873549]\n",
            " [0.59483749]]\n",
            "\n",
            "Value of z2:\n",
            "[[1.36127024]]\n",
            "Value of a2:\n",
            "[[0.79596607]]\n",
            "\n",
            "0.8209757904998143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Code"
      ],
      "metadata": {
        "id": "JObkuUYH0ATB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target_dir = \"/content/drive/My Drive/\"\n",
        "# filename = \"blarg.json\"\n",
        "# fileRoute = f\"{target_dir}/{filename}\"\n",
        "\n",
        "# with open(fileRoute, 'w') as outfile:\n",
        "#     some_data = {\n",
        "#         \"a1\": [[1, 2], [3, 4]],\n",
        "#         \"b1\": [[5, 6], [7, 8]]\n",
        "#     }\n",
        "\n",
        "#     outfile.write(json.dumps(some_data))\n",
        "\n",
        "# Compute error for an individual output of the neural network\n",
        "def compute_one_instance_err(expVal, predVal):\n",
        "    return -expVal * np.log(predVal) - (1 - expVal) * np.log(1 - predVal)\n",
        "\n",
        "def multiply(a, b):\n",
        "    return a * b\n",
        "\n",
        "\n",
        "vectorFunction = np.vectorize(multiply)\n",
        "a = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "colSum = np.sum(a, axis=0)\n",
        "rowSum = np.sum(a, axis=1)\n",
        "\n",
        "print(colSum)\n",
        "print(rowSum)\n",
        "print(f\"Sum of all elements in matrix: {np.sum(colSum)}\")\n",
        "\n",
        "b = np.array([\n",
        "    [3],\n",
        "    [7]\n",
        "])\n",
        "\n",
        "print(f\"b-vector elements squared:\\n{np.multiply(b, b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wQR5HQY0BkY",
        "outputId": "717b7386-ee29-4b01-a966-0200c08d291e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 6]\n",
            "[3 7]\n",
            "Sum of all elements in matrix: 10\n",
            "b-vector elements squared:\n",
            "[[ 9]\n",
            " [49]]\n"
          ]
        }
      ]
    }
  ]
}