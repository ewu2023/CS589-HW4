{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewu2023/CS589-HW4/blob/main/CS589_NeuralNets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg570F-XxICR"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEWGG2M_xNfo",
        "outputId": "e1e69f68-52a1-4ac7-c237-856824dc5303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B-JBg83M1ok"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WsRlxN3fLmfw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "\n",
        "# For reading/writing to files\n",
        "import json\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOW3NjBRNpsU"
      },
      "source": [
        "# Define Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "PlC7io6JNYw8"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self, networkShape, trainData: pd.DataFrame, classLabels, weights=None, regParam=0, alpha=0.01, epsilon=0.01, debugFlag=False):\n",
        "        \"\"\"\n",
        "        Constructor for the neural network class.\n",
        "        \n",
        "        networkShape: A list of integers that contains the number of neurons to use in each layer\n",
        "\n",
        "        trainData: The data set that will be used to train the model\n",
        "\n",
        "        weights: A list of weight matrices for each hidden layer. If initialized to None, the constructor will assign random weights\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Process training data\n",
        "        \"\"\"\n",
        "        self.trainData = trainData.sample(frac=1)\n",
        "        \n",
        "        # Get a copy of the training data without the labels\n",
        "        self.noLabelTrainData = trainData.loc[:, ~trainData.columns.isin(classLabels)]\n",
        "        self.classLabels = classLabels\n",
        "\n",
        "        # Encode class vectors\n",
        "        self.classVectors = {}\n",
        "        for i in range(len(trainData)):\n",
        "            # Get current row from training data\n",
        "            row = trainData.iloc[i]\n",
        "\n",
        "            # Iterate over all classes and assign values\n",
        "            classVector = {}\n",
        "            for label in classLabels:\n",
        "                expVal = row[label]\n",
        "                classVector[label] = [expVal]\n",
        "\n",
        "            # Convert class vector to numpy array\n",
        "            classVecDf = pd.DataFrame(classVector)\n",
        "\n",
        "            # Append class vector to dictionary of vectors\n",
        "            # Implementation uses column vectors, so we take transpose here\n",
        "            self.classVectors[i] = (classVecDf.to_numpy()).T\n",
        "\n",
        "        self.networkShape = networkShape\n",
        "\n",
        "        # Set the value of the regularization parameter\n",
        "        self.regParam = regParam\n",
        "\n",
        "        # Set the step size for gradient descent\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Set value of epsilon for stopping condition\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        # Set debug flag to show output of intermediate computations\n",
        "        self.debugFlag = debugFlag\n",
        "\n",
        "        # Instance variable storing weight matrices\n",
        "        self.layers = []\n",
        "        \n",
        "        # Initialize layers\n",
        "        for i in range(len(networkShape) - 1):\n",
        "            # Get the number of neurons in the current and next layers\n",
        "            numCurLayer = networkShape[i] + 1 # Account for neurons + bias term in current layer\n",
        "            numNextLayer = networkShape[i + 1]\n",
        "\n",
        "            # Initialize matrix for the current layer\n",
        "            # Number of rows = number of neurons in layer i + 1\n",
        "            # Number of columns = number of neurons in layer i\n",
        "            layerMatrix = np.zeros(shape=(numNextLayer, numCurLayer))\n",
        "            if weights:\n",
        "                layerMatrix = weights[i]\n",
        "            else:\n",
        "                self._init_matrix(layerMatrix)\n",
        "            \n",
        "            # Append current layer to the list of layers\n",
        "            self.layers.append(layerMatrix)\n",
        "        \n",
        "    def _init_matrix(self, matrix: np.ndarray):\n",
        "        rows, cols = matrix.shape\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                matrix[i, j] = norm.rvs()\n",
        "    \n",
        "    # Definition for the sigmoid function\n",
        "    def sigmoid(self, x):\n",
        "        return (1 / (1 + np.exp(-x)))\n",
        "    \n",
        "    # Compute activation vector\n",
        "    def compute_activation_vector(self, weightedSums: np.ndarray):\n",
        "        numRows, numCols = weightedSums.shape\n",
        "        activationVector = np.zeros(shape=(numRows, numCols))\n",
        "\n",
        "        for i in range(numRows):\n",
        "            # Get weighted sum from i-th row\n",
        "            x = weightedSums[i, 0]\n",
        "\n",
        "            # Compute output of sigmoid function and place it in activation vector\n",
        "            activationVector[i, 0] = self.sigmoid(x)\n",
        "        \n",
        "        return activationVector\n",
        "    \n",
        "    # Method for propagating forward one instance\n",
        "    def propagate_one(self, instance, activations=None, printOut=False):\n",
        "        # Add a bias term to the instance\n",
        "        instanceAsNP = instance.to_numpy()\n",
        "        instanceVector = np.concatenate(([1], instanceAsNP))\n",
        "        \n",
        "        # Make instance vector a column vector\n",
        "        instanceVector = np.atleast_2d(instanceVector).T\n",
        "        \n",
        "        # Iterate over each layer and compute activations for each neuron\n",
        "        prevActivation = instanceVector # Keep track of the activation vector for previous layer\n",
        "\n",
        "        if activations != None: # If activations is not None, append current activation\n",
        "            activations.append(prevActivation)\n",
        "\n",
        "        # If the debug flag was set, print out the first instance vector\n",
        "        if printOut:\n",
        "            print(f\"Value of a0:\\n{prevActivation}\\n\")\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            # Get current weight matrix\n",
        "            curTheta = self.layers[i]\n",
        "\n",
        "            # Compute weighted sum vector (z-matrix): Theta^{l=i-1} * a^{l=i-1}\n",
        "            z = np.matmul(curTheta, prevActivation)\n",
        "\n",
        "            # Compute activation vector of current layer\n",
        "            curActivationVec = self.compute_activation_vector(z)\n",
        "            \n",
        "            # Add bias term to current activation vector\n",
        "            curActivationVec = np.concatenate(([[1]], curActivationVec)) # Prepend 1 to vector\n",
        "\n",
        "            # Update previous activation vector\n",
        "            prevActivation = curActivationVec\n",
        "\n",
        "            # Append current activation to list\n",
        "            if activations != None:\n",
        "                activations.append(curActivationVec)\n",
        "\n",
        "            # Print results of computation at this step if debug flag is on\n",
        "            if printOut:\n",
        "                print(f\"Value of z{i + 1}:\\n{z}\")\n",
        "                print(f\"Value of a{i + 1}:\\n{curActivationVec}\\n\")\n",
        "        \n",
        "        # Compute activation at the final layer\n",
        "        lastTheta = self.layers[len(self.layers) - 1]\n",
        "        lastZMat = np.matmul(lastTheta, prevActivation)\n",
        "        outputVector = self.compute_activation_vector(lastZMat)\n",
        "\n",
        "        # If the debug flag was set, print results of this final computation\n",
        "        if printOut:\n",
        "            print(f\"Value of z{len(self.layers)}:\\n{lastZMat}\")\n",
        "            print(f\"Value of a{len(self.layers)}:\\n{outputVector}\\n\")\n",
        "\n",
        "        if activations != None:\n",
        "            activations.append(outputVector)\n",
        "\n",
        "        # Return as a vector in the event there are multiple outputs\n",
        "        return outputVector\n",
        "\n",
        "    # Compute error for an individual output of the neural network\n",
        "    def compute_one_instance_err(self, expVal, predVal):\n",
        "        return -expVal * np.log(predVal) - (1 - expVal) * np.log(1 - predVal)\n",
        "\n",
        "    # Helper method for computing regularized error\n",
        "    def compute_error(self, df:pd.DataFrame, printOut=False):\n",
        "        # Keep track of total error across all training instances\n",
        "        totalErr = 0\n",
        "\n",
        "        # Iterate over all training instances\n",
        "        for i in range(len(df)):\n",
        "            # Get current instance and perform forward propagation on it\n",
        "            curInstance = df.iloc[i]\n",
        "            predVector = self.propagate_one(curInstance, printOut=False) # Will be a vector\n",
        "            # Get the expected values vector\n",
        "            expVector = self.classVectors[i]\n",
        "\n",
        "            # Compute error vector\n",
        "            vectorizedErrorFunc = np.vectorize(self.compute_one_instance_err)\n",
        "            errVector = vectorizedErrorFunc(expVector, predVector)\n",
        "\n",
        "            if printOut:\n",
        "                print(f\"Cost associated with Instance {i}: {np.sum(errVector)}\\n\")\n",
        "            # Sum all elements of error vector, then add it to total error\n",
        "            totalErr += np.sum(errVector)\n",
        "        \n",
        "        # Compute average error\n",
        "        avgErr = totalErr / len(df)\n",
        "\n",
        "        \"\"\" Compute the squared sum of all weights in the network \"\"\"\n",
        "        weightSqSum = 0\n",
        "        for weightMatrix in self.layers:\n",
        "            # Square all of the weights\n",
        "            squaredMatrix = np.multiply(weightMatrix, weightMatrix)\n",
        "\n",
        "            # Drop bias terms from squared matrix\n",
        "            rows, cols = squaredMatrix.shape\n",
        "            zeroColumn = np.zeros(rows)\n",
        "            squaredMatrix[:, 0] = zeroColumn\n",
        "\n",
        "            # Add all columns, then add each column's total to get the total sum for this matrix\n",
        "            colSums = np.sum(squaredMatrix, axis=0)\n",
        "            matrixTotal = np.sum(colSums)\n",
        "\n",
        "            # Add matrix total to sum of the weights squared\n",
        "            weightSqSum += matrixTotal\n",
        "        \n",
        "        # Regularize error\n",
        "        weightSqSum *= (self.regParam / (2 * len(df)))\n",
        "\n",
        "        # Return error + regularization term\n",
        "        return avgErr + weightSqSum\n",
        "    \n",
        "    def process_batch(self, startIndex, endIndex):\n",
        "        # Initialize gradients for each layer\n",
        "        # Accumulate the gradients in this list\n",
        "        gradients = []\n",
        "        for layer in self.layers:\n",
        "            # Get the shape of each layer\n",
        "            rows, cols = layer.shape\n",
        "            gradients.append(np.zeros(shape=(rows,cols)))\n",
        "        \n",
        "        for i in range(startIndex, endIndex):\n",
        "            if self.debugFlag:\n",
        "                print(f\"--- Propagating Instance {i} ---\\n\")\n",
        "\n",
        "            # Propagate current instance through the network\n",
        "            curInstance = self.noLabelTrainData.iloc[i]\n",
        "            activations_i = []\n",
        "            self.propagate_one(curInstance, activations=activations_i, printOut=self.debugFlag)\n",
        "\n",
        "            # Compute delta values for output layer\n",
        "            outputVector = activations_i[len(activations_i) - 1]\n",
        "            if self.debugFlag:\n",
        "                print(f\"Instance {i} Activation: {outputVector.T}\\n\")\n",
        "\n",
        "            expectedVector = self.classVectors[i]\n",
        "\n",
        "            delta_vectors = []\n",
        "            delta_vectors.append(outputVector - expectedVector)\n",
        "\n",
        "            # Iterate over each layer and compute delta values\n",
        "            for k in range(len(self.layers) - 1, 0, -1):\n",
        "                # Get current weight matrix\n",
        "                weightMatrix = self.layers[k]\n",
        "                delta_next = delta_vectors[0]\n",
        "\n",
        "                # Compute delta values for nodes in current layer\n",
        "                a = np.matmul(weightMatrix.T, delta_next)\n",
        "                b = np.multiply(a, activations_i[k])\n",
        "                delta_k = np.multiply(b, (1 - activations_i[k]))\n",
        "\n",
        "                # Remove bias term from delta_k\n",
        "                delta_k = np.delete(delta_k, 0, 0)\n",
        "\n",
        "                # Append to delta vectors\n",
        "                delta_vectors.insert(0, delta_k)\n",
        "\n",
        "            # Accumulate the gradients for each layer\n",
        "            if self.debugFlag:\n",
        "                print(f\"Instance {i} Deltas:\\n\")\n",
        "                for deltaIndex in range(len(delta_vectors)):\n",
        "                    print(f\"Deltas for Layer {deltaIndex}:\\n{delta_vectors[deltaIndex]}\\n\")\n",
        "            \n",
        "            for j in range(len(self.layers) - 1, -1, -1):\n",
        "                curGradLayer = gradients[j]\n",
        "\n",
        "                # Compute gradients of this instance for current layer\n",
        "                gradMatrix = np.matmul(delta_vectors[j], activations_i[j].T)\n",
        "                if self.debugFlag:\n",
        "                    print(f\"Gradients of Theta{j} on instance {i}:\\n{gradMatrix}\\n\")\n",
        "\n",
        "                # Accumulate the gradients\n",
        "                curGradLayer = curGradLayer + gradMatrix\n",
        "                gradients[j] = curGradLayer\n",
        "\n",
        "        # Iterate over each layer and compute gradient + regularization factor\n",
        "        for i in range(len(self.layers) - 1, -1, -1):\n",
        "            regFactor = np.multiply(self.regParam, self.layers[i])\n",
        "            # Set first col of regFactor to 0s\n",
        "            rows, cols = regFactor.shape\n",
        "            regFactor[:,0] = np.zeros(rows)\n",
        "\n",
        "            curGradLayer = gradients[i]\n",
        "\n",
        "            curGradLayer = (1 / len(self.trainData)) * (curGradLayer + regFactor)\n",
        "            gradients[i] = curGradLayer\n",
        "\n",
        "        # Print error cost and final gradients\n",
        "        if self.debugFlag:\n",
        "            print(\"----------\")\n",
        "            print(f\"Final (regularized) cost J based on Entire Set: {self.compute_error(self.noLabelTrainData, printOut=True)}\")\n",
        "            print(f\"Final Average, Regularized Gradients:\\n\")\n",
        "            for gradIndex in range(len(gradients)):\n",
        "                print(f\"Final Regularized gradients of Theta{gradIndex}:\\n{gradients[gradIndex]}\\n\")\n",
        "\n",
        "        # Update weights according to gradients\n",
        "        for i in range(len(self.layers) - 1, -1, -1):\n",
        "            self.layers[i] = self.layers[i] - self.alpha * gradients[i]\n",
        "\n",
        "    def backpropagate(self, batches=10):\n",
        "        # Determine current error across entire data set \n",
        "        prevErr = self.compute_error(self.noLabelTrainData, printOut=False)\n",
        "        converged = False\n",
        "\n",
        "        # Parameters for mini-batch\n",
        "        batchSize = len(self.noLabelTrainData) // batches\n",
        "\n",
        "        # iterations = 500\n",
        "        curIter = 1\n",
        "        while not converged:\n",
        "            startIndex = 0\n",
        "            for i in range(batches - 1):\n",
        "                # Determine where to end the batch\n",
        "                endIndex = startIndex + batchSize\n",
        "\n",
        "                # Process the batch\n",
        "                self.process_batch(startIndex, endIndex)\n",
        "\n",
        "                # Update start index\n",
        "                startIndex += batchSize\n",
        "            \n",
        "            # Process the last batch\n",
        "            self.process_batch(startIndex, len(self.noLabelTrainData))\n",
        "                \n",
        "            # Compute current error and check for stopping condition\n",
        "            curErr = self.compute_error(self.noLabelTrainData, printOut=False)\n",
        "            if np.absolute(prevErr - curErr) <= self.epsilon:\n",
        "                # If the difference in error is equal to or smaller than\n",
        "                # the given value of epsilon, consider the network as converged\n",
        "                converged = True\n",
        "                continue\n",
        "            \n",
        "            # Update previous error\n",
        "            prevErr = curErr\n",
        "\n",
        "            # print(f\"Error at Iteration {curIter}: {prevErr}\")\n",
        "\n",
        "            # Update iterations\n",
        "            curIter += 1\n",
        "        \n",
        "    def train_network(self, batchSize=10):\n",
        "        self.backpropagate(batchSize)\n",
        "    \n",
        "    def classify_instance(self, instance, labelledInstance):\n",
        "        # Propagate instance through the network\n",
        "        output = self.propagate_one(instance)\n",
        "\n",
        "        # Get expected vector\n",
        "        # expVector = []\n",
        "        # for label in self.classLabels:\n",
        "        #     expVector.append([labelledInstance[label]])\n",
        "        \n",
        "        # expVectorNP = np.array(expVector)\n",
        "        \n",
        "        # errFunc = np.vectorize(self.compute_one_instance_err)\n",
        "        # print(errFunc(expVectorNP, output))\n",
        "\n",
        "        # Determine which class produced highest probability\n",
        "        rows, cols = output.shape\n",
        "        maxProb = -1\n",
        "        maxClass = 0\n",
        "        for i in range(rows):\n",
        "            outputProb = output[i, 0]\n",
        "            if outputProb > maxProb:\n",
        "                maxProb = outputProb\n",
        "                maxClass = i\n",
        "        \n",
        "        predLabel = \"class_none\"\n",
        "        for label in self.classLabels:\n",
        "            labelIndex = self.classLabels[label]\n",
        "            if labelIndex == maxClass:\n",
        "                predLabel = label\n",
        "                break\n",
        "        \n",
        "        # Return class with highest probability\n",
        "        return predLabel, maxProb, output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxzyGtabHfub"
      },
      "source": [
        "Test Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8_y6PpYnHiGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154c63ba-8b81-4549-d092-12af413e68a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Propagating Instance 0 ---\n",
            "\n",
            "Value of a0:\n",
            "[[1.  ]\n",
            " [0.13]]\n",
            "\n",
            "Value of z1:\n",
            "[[0.413]\n",
            " [0.326]]\n",
            "Value of a1:\n",
            "[[1.       ]\n",
            " [0.601807 ]\n",
            " [0.5807858]]\n",
            "\n",
            "Value of z2:\n",
            "[[1.34937498]]\n",
            "Value of a2:\n",
            "[[0.79402743]]\n",
            "\n",
            "Instance 0 Activation: [[0.79402743]]\n",
            "\n",
            "Instance 0 Deltas:\n",
            "\n",
            "Deltas for Layer 0:\n",
            "[[-0.01269739]\n",
            " [-0.01548092]]\n",
            "\n",
            "Deltas for Layer 1:\n",
            "[[-0.10597257]]\n",
            "\n",
            "Gradients of Theta1 on instance 0:\n",
            "[[-0.10597257 -0.06377504 -0.06154737]]\n",
            "\n",
            "Gradients of Theta0 on instance 0:\n",
            "[[-0.01269739 -0.00165066]\n",
            " [-0.01548092 -0.00201252]]\n",
            "\n",
            "--- Propagating Instance 1 ---\n",
            "\n",
            "Value of a0:\n",
            "[[1.  ]\n",
            " [0.42]]\n",
            "\n",
            "Value of z1:\n",
            "[[0.442]\n",
            " [0.384]]\n",
            "Value of a1:\n",
            "[[1.        ]\n",
            " [0.60873549]\n",
            " [0.59483749]]\n",
            "\n",
            "Value of z2:\n",
            "[[1.36127024]]\n",
            "Value of a2:\n",
            "[[0.79596607]]\n",
            "\n",
            "Instance 1 Activation: [[0.79596607]]\n",
            "\n",
            "Instance 1 Deltas:\n",
            "\n",
            "Deltas for Layer 0:\n",
            "[[0.06739994]\n",
            " [0.08184068]]\n",
            "\n",
            "Deltas for Layer 1:\n",
            "[[0.56596607]]\n",
            "\n",
            "Gradients of Theta1 on instance 1:\n",
            "[[0.56596607 0.34452363 0.33665784]]\n",
            "\n",
            "Gradients of Theta0 on instance 1:\n",
            "[[0.06739994 0.02830797]\n",
            " [0.08184068 0.03437309]]\n",
            "\n",
            "----------\n",
            "Cost associated with Instance 0: 0.36557477431084995\n",
            "\n",
            "Cost associated with Instance 1: 1.2763768066887786\n",
            "\n",
            "Final (regularized) cost J based on Entire Set: 0.8209757904998143\n",
            "Final Average, Regularized Gradients:\n",
            "\n",
            "Final Regularized gradients of Theta0:\n",
            "[[0.02735127 0.01332866]\n",
            " [0.03317988 0.01618028]]\n",
            "\n",
            "Final Regularized gradients of Theta1:\n",
            "[[0.22999675 0.1403743  0.13755523]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def backprop_example_1():\n",
        "    d = {\n",
        "        'x': [0.13000, 0.42000], \n",
        "        'class': [0.90000, 0.23000]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data=d)\n",
        "    df_noLabels = df.loc[:, df.columns!='class']\n",
        "\n",
        "    networkShape = [1, 2, 1]\n",
        "    weights = [\n",
        "        np.array(\n",
        "            [[0.40000, 0.10000],\n",
        "            [0.30000, 0.20000]],\n",
        "        ),\n",
        "\n",
        "        np.array([[0.70000, 0.50000, 0.60000]])\n",
        "    ]\n",
        "\n",
        "    classLabels = ['class']\n",
        "    network = NeuralNetwork(networkShape, trainData=df, classLabels=classLabels, weights=weights, debugFlag=True)\n",
        "    network.backpropagate(batches=1)\n",
        "\n",
        "def backprop_example_2():\n",
        "    # Pre-process data\n",
        "    d = {\n",
        "        \"x1\": [0.32000, 0.83000],\n",
        "        \"x2\": [0.68000, 0.02000],\n",
        "        \"y1\": [0.75000, 0.75000],\n",
        "        \"y2\": [0.98000, 0.28000]\n",
        "    }\n",
        "\n",
        "    classLabels = [\"y1\", \"y2\"]\n",
        "\n",
        "    df = pd.DataFrame(d)\n",
        "    df_noLabels = df.loc[:, ~df.columns.isin(classLabels)]\n",
        "    \n",
        "    # Initialize network\n",
        "    networkShape = [2, 4, 3, 2]\n",
        "    weights = [\n",
        "        np.array([\n",
        "            [0.42000, 0.15000, 0.40000],\n",
        "            [0.72000, 0.10000, 0.54000],\n",
        "            [0.01000, 0.19000, 0.42000],\n",
        "            [0.30000, 0.35000, 0.68000]\n",
        "        ]),\n",
        "\n",
        "        np.array([\n",
        "            [0.21000, 0.67000, 0.14000, 0.96000, 0.87000],\n",
        "            [0.87000, 0.42000, 0.20000, 0.32000, 0.89000],\n",
        "            [0.03000, 0.56000, 0.80000, 0.69000, 0.09000]\n",
        "        ]),\n",
        "\n",
        "        np.array([\n",
        "            [0.04000,  0.87000,  0.42000,  0.53000],\n",
        "            [0.17000,  0.10000,  0.95000,  0.69000]\n",
        "        ])\n",
        "    ]\n",
        "\n",
        "    network = NeuralNetwork(\n",
        "        networkShape, \n",
        "        df, \n",
        "        classLabels=classLabels, \n",
        "        weights=weights, \n",
        "        regParam=0.25, \n",
        "        debugFlag=True\n",
        "    )\n",
        "\n",
        "    network.backpropagate(batches=1)\n",
        "\n",
        "backprop_example_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqkfs67QkGIU"
      },
      "source": [
        "# Data Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMAkNILplX5b"
      },
      "source": [
        "Load CSV Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v8PaCttDkHcD"
      },
      "outputs": [],
      "source": [
        "# Regular expressions for integers and floats\n",
        "FLOAT_REGEX = \"[-+]?[0-9]+\\.[0-9]+\"\n",
        "INTEGER_REGEX = \"[-+]?[0-9]+\"\n",
        "def loadCSV(filename, delimeter):\n",
        "    with open (filename) as csvfile:\n",
        "        reader = csv.DictReader(csvfile, delimiter=delimeter)\n",
        "        i = 0\n",
        "        data_table = []\n",
        "        for row in reader:\n",
        "            # Create a new row in the data table\n",
        "            data_table.append({})\n",
        "            cur_table_row = data_table[i]\n",
        "\n",
        "            # Copy over each column volume into the new row\n",
        "            for col in row:\n",
        "                col_lower = col.lower()\n",
        "                if \"class\" in col_lower:\n",
        "                    cur_table_row['class'] = row[col]\n",
        "                else:\n",
        "                    cur_table_row[col_lower] = row[col]\n",
        "            i += 1\n",
        "        \n",
        "        df = pd.DataFrame(data_table)\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fVH_M1ptWre"
      },
      "source": [
        "Assign Data Types to Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4sjsJksXtag-"
      },
      "outputs": [],
      "source": [
        "# Attempts to assign data types to each column and value, depending on format\n",
        "def parseTypes(df: pd.DataFrame, attrTypes=None):\n",
        "    data_table = []\n",
        "    for i in range(len(df)):\n",
        "        # Get current row in dataframe\n",
        "        row = df.iloc[i]\n",
        "\n",
        "        # Create new row in the table\n",
        "        data_table.append({})\n",
        "        cur_table_row = data_table[i]\n",
        "\n",
        "        # Copy over each column volume into the new row\n",
        "        for col in df:\n",
        "            col_lower = col.lower()\n",
        "            if 'class' in col_lower:\n",
        "                # Copy value of class to current row in table\n",
        "                cur_table_row['class'] = row[col]\n",
        "            else:\n",
        "                cur_value = row[col]\n",
        "                colType = None\n",
        "                # Check if a type for the current attribute was specified\n",
        "                if attrTypes:\n",
        "                    if col in attrTypes:\n",
        "                        colType = attrTypes[col]\n",
        "                \n",
        "                if colType == 'categorical' or colType == None:\n",
        "                    # Store value as a string\n",
        "                    cur_table_row[col_lower] = cur_value\n",
        "                else:\n",
        "                    if re.fullmatch(FLOAT_REGEX, cur_value):\n",
        "                        # Store this value as a float\n",
        "                        cur_table_row[col_lower] = float(cur_value)\n",
        "                    else:\n",
        "                        # Store this value as an integer\n",
        "                        cur_table_row[col_lower] = int(cur_value)\n",
        "    \n",
        "    # Return the data frame with the formatted values\n",
        "    formattedDf = pd.DataFrame(data_table)\n",
        "    return formattedDf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrBgy78aQuiL"
      },
      "source": [
        "Partition Data Set by Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JAHy2cJEQ5bM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Select rows of dataframe where given column is == val\n",
        "\"\"\"\n",
        "def select_EQ(df: pd.DataFrame, col: str, val):\n",
        "    view = df.loc[df[col] == val]\n",
        "    return view\n",
        "\n",
        "\"\"\" Partition a given data set by class \"\"\"\n",
        "def partition_by_class(df: pd.DataFrame, classCols):\n",
        "    classViews = {}\n",
        "    for label in classCols:\n",
        "        classViews[label] = df.loc[df[label] == 1]\n",
        "\n",
        "    return classViews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l66piRYJRLzD"
      },
      "source": [
        "Split into k-Stratified Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xj81pFGnRTjb"
      },
      "outputs": [],
      "source": [
        "def split_into_folds(df: pd.DataFrame,  k):\n",
        "    # Determine the size for each fold\n",
        "    foldSize = len(df) // k\n",
        "    remaining = len(df) % k\n",
        "\n",
        "    # Generate the folds\n",
        "    folds = []\n",
        "    foldEnd = 0\n",
        "    for i in range(k):\n",
        "        foldStart = i * foldSize\n",
        "        foldEnd = foldStart + foldSize\n",
        "        folds.append(df[foldStart:foldEnd])\n",
        "    \n",
        "    # Append remaining instances to the last fold, if there are any\n",
        "    if remaining > 0:\n",
        "        lastFold = folds[len(folds) - 1]\n",
        "        newLastFold = pd.concat([lastFold, df[foldEnd:len(df)]])\n",
        "        folds[len(folds) - 1] = newLastFold\n",
        "\n",
        "    return folds\n",
        "\n",
        "def generate_stratified_folds(df: pd.DataFrame, classCols, k=10):\n",
        "    # Partition data by class first\n",
        "    classDFs = partition_by_class(df, classCols)\n",
        "\n",
        "    # Split each class dataframe into k-subsets\n",
        "    classFolds = {}\n",
        "    for label in classDFs:\n",
        "        labelData = classDFs[label]\n",
        "        classFolds[label] = split_into_folds(labelData, k)\n",
        "    \n",
        "    # Merge corresponding folds for each class together\n",
        "    folds = []\n",
        "    for i in range(k):\n",
        "        dfsToMerge = []\n",
        "        for label in classFolds:\n",
        "            # Add the i-th subset for the class data into the merge list\n",
        "            dfsToMerge.append(classFolds[label][i])\n",
        "        \n",
        "        # Create the new fold\n",
        "        folds.append(pd.concat(dfsToMerge))\n",
        "    \n",
        "    return folds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTFf72suyvP3"
      },
      "source": [
        "# Process Data Sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute F1"
      ],
      "metadata": {
        "id": "pxUZOsGtHlBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_multiclass_measures(confusionMatrix: np.ndarray):\n",
        "    # Initialize counters for precision and recall\n",
        "    sumPre = 0\n",
        "    sumRec = 0\n",
        "\n",
        "    # Compute precision and recall by class\n",
        "    numRows, numCols = confusionMatrix.shape\n",
        "    for i in range(numRows):\n",
        "        # Set i as the positive class\n",
        "        posClass = i\n",
        "\n",
        "        # Set counters for TP, TN, FP, FN\n",
        "        tp = 0\n",
        "        tn = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "\n",
        "        for j in range(numRows):\n",
        "            for k in range(numCols):\n",
        "                if j == posClass and k == posClass: # The positive class\n",
        "                    tp += confusionMatrix[j, k]\n",
        "                elif j != posClass and k == posClass: # False positives\n",
        "                    fp += confusionMatrix[j, k]\n",
        "                elif j != posClass and k != posClass: # True negatives\n",
        "                    tn += confusionMatrix[j, k]\n",
        "                else: # False negatives\n",
        "                    fn += confusionMatrix[j, k]\n",
        "        \n",
        "        # Compute measures for the current positive class\n",
        "        pre = tp / (tp + fp) if tp != 0 or fp != 0 else 0\n",
        "        rec = tp / (tp + fn) if tp != 0 or fp != 0 else 0\n",
        "        \n",
        "        # Add precision and recall to running total\n",
        "        sumPre += pre\n",
        "        sumRec += rec\n",
        "    \n",
        "    # Compute average precision and recall\n",
        "    avgPre = sumPre / numRows\n",
        "    avgRec = sumRec / numRows\n",
        "\n",
        "    # Compute accuracy\n",
        "    numInstances = 0\n",
        "    numCorrect = 0\n",
        "    for row in range(numRows):\n",
        "        for col in range(numCols):\n",
        "            numInstances += confusionMatrix[row, col]\n",
        "            if row == col: # Entries along diagonal were correctly identified instances\n",
        "                numCorrect += confusionMatrix[row, col]\n",
        "    \n",
        "    accuracy = numCorrect / numInstances\n",
        "\n",
        "    # Compute Macro F1 score\n",
        "    macroF1 = 2 * (avgPre * avgRec) / (avgPre + avgRec)\n",
        "\n",
        "    return (accuracy, avgPre, avgRec, macroF1)"
      ],
      "metadata": {
        "id": "v7QPRCeWHnO4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vtEKmqQgyyZI"
      },
      "outputs": [],
      "source": [
        "def run_model(df: pd.DataFrame, layerStructure, regParam=0, alpha=0.01, epsilon=0.01):\n",
        "    \"\"\"\n",
        "    Run the neural network using the given data set and parameters.\n",
        "\n",
        "    `df`: Data set to train and evalute the neural network on\n",
        "\n",
        "    `classLabels`: Set of strings representing which columns/attributes to treat as classes\n",
        "\n",
        "    `regParam`: Value of the regularization coefficient to use\n",
        "\n",
        "    `alpha`: Value of step size to use in batch gradient descent\n",
        "    \n",
        "    `epsilon`: Minimum tolerance for error improvement. Used as a stopping condition for gradient descent updates.\n",
        "    \"\"\"\n",
        "    # Shuffle the data set\n",
        "    df = df.sample(frac=1)\n",
        "\n",
        "    # Get one hot encoded version of data set\n",
        "    oneHotDf = pd.get_dummies(df)\n",
        "\n",
        "    # From the entire data set, determine its class labels and features\n",
        "    classLabels = {}\n",
        "    features = set()\n",
        "    index = 0\n",
        "    for col in oneHotDf:\n",
        "        if \"class\" in col:\n",
        "            classLabels[col] = index\n",
        "            index += 1\n",
        "        else:\n",
        "            features.add(col)\n",
        "    \n",
        "    # Generate stratified folds\n",
        "    dataFolds = generate_stratified_folds(oneHotDf, classLabels)\n",
        "    unlabelledFolds = []\n",
        "    for fold in dataFolds:\n",
        "        unlabelledFolds.append(fold.loc[:, ~fold.columns.isin(classLabels)])\n",
        "\n",
        "    # Determine the shape of the network to use\n",
        "    networkShape = [len(features)]\n",
        "    networkShape = networkShape + layerStructure\n",
        "    networkShape.append(len(classLabels))\n",
        "\n",
        "    # Perform cross-fold validation\n",
        "    avgAcc = 0\n",
        "    avgF1 = 0\n",
        "    for i in range(len(dataFolds)):\n",
        "        # Get test data\n",
        "        testData = dataFolds[i]\n",
        "        testNoLabels = unlabelledFolds[i]\n",
        "\n",
        "        # Create training data set\n",
        "        trainFolds = []\n",
        "        for j in range(len(dataFolds)):\n",
        "            if j != i:\n",
        "                trainFolds.append(dataFolds[j])\n",
        "        trainData = pd.concat(trainFolds)\n",
        "\n",
        "        # Create and train network\n",
        "        nn = NeuralNetwork(\n",
        "            networkShape, \n",
        "            trainData, \n",
        "            classLabels,\n",
        "            regParam=regParam,\n",
        "            alpha=alpha,\n",
        "            epsilon=epsilon\n",
        "        )\n",
        "\n",
        "        nn.train_network()\n",
        "\n",
        "        # Propagate each instance through network\n",
        "        # Create confusion matrix\n",
        "        confusionMatrix = np.zeros(shape=(len(classLabels), len(classLabels)), dtype=int)\n",
        "\n",
        "        for k in range(len(testNoLabels)):\n",
        "            instance = testNoLabels.iloc[k]\n",
        "            labelled = testData.iloc[k]\n",
        "            predicted, maxProb, probs = nn.classify_instance(instance, labelled)\n",
        "\n",
        "            # Determine expected class\n",
        "            expected = 'class_none'\n",
        "            for label in classLabels:\n",
        "                if labelled[label] == 1:\n",
        "                    expected = label\n",
        "                    break\n",
        "            \n",
        "            # print(f\"Predicted: {predicted}\\nOutput:{probs}\")\n",
        "            # print(f\"Expected: {expected}\\n\")\n",
        "\n",
        "            # Get correct element to update in confusion matrix\n",
        "            row = classLabels[expected]\n",
        "            col = classLabels[predicted]\n",
        "\n",
        "            # Update confusion matrix\n",
        "            confusionMatrix[row, col] += 1\n",
        "        \n",
        "        # Compute measures\n",
        "        acc, pre, rec, f1 = compute_multiclass_measures(confusionMatrix)\n",
        "        avgAcc += acc\n",
        "        avgF1 = f1\n",
        "    # --- END FOR ---\n",
        "    print(f\"Structure: {networkShape}\")\n",
        "    print(f\"Average Accuracy: {avgAcc / len(dataFolds)}\")\n",
        "    print(f\"Average F1: {avgF1 / len(dataFolds)}\")\n",
        "\n",
        "    return (avgAcc / len(dataFolds), avgF1 / len(dataFolds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYYGhkeG3G24"
      },
      "source": [
        "Define Data Processing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j4yvpucg3JBR"
      },
      "outputs": [],
      "source": [
        "target_dir = \"/content/drive/My Drive/Colab Notebooks/cs589/data\"\n",
        "WINE_CSV = f\"{target_dir}/hw3_wine.csv\"\n",
        "HOUSE_CSV = f\"{target_dir}/hw3_house_votes_84.csv\"\n",
        "\n",
        "def process_wine(networkShape, regParam, outfile):\n",
        "    wineData = loadCSV(WINE_CSV, '\\t')\n",
        "    \n",
        "    # Set attribute value map\n",
        "    attrTypes = {}\n",
        "    for col in wineData.columns:\n",
        "        if col != \"class\":\n",
        "            attrTypes[col] = 'numerical'\n",
        "    \n",
        "    # Parse data types\n",
        "    wineData = parseTypes(wineData, attrTypes)\n",
        "    wineNoLabels = wineData.loc[:, wineData.columns!='class']\n",
        "    \n",
        "    # Normalize data set\n",
        "    wineNormal = (wineNoLabels - wineNoLabels.min()) / (wineNoLabels.max() - wineNoLabels.min())\n",
        "    wineNormal['class'] = wineData['class']\n",
        "\n",
        "    # Pass wine data set through model\n",
        "    # Will automatically one-hot encode class column\n",
        "    acc, f1 = run_model(wineNormal, networkShape, regParam=regParam, alpha=1)\n",
        "\n",
        "    with open(outfile, 'w') as writer:\n",
        "        outJson = {\n",
        "            f\"{networkShape}\": {\n",
        "                \"lambda\": regParam,\n",
        "                \"acc\": acc,\n",
        "                \"f1\": f1\n",
        "            }\n",
        "        }\n",
        "        writer.write(json.dumps(outJson))\n",
        "    \n",
        "def process_house(networkShape, regParam, outfile):\n",
        "    # Load in raw CSV\n",
        "    houseData = loadCSV(HOUSE_CSV, ',')\n",
        "\n",
        "    # Data already loaded as all categorical, so just pass it to run_model\n",
        "    # Will one-hot encode categorical and class columns\n",
        "    acc, f1 = run_model(houseData, networkShape, regParam=regParam, alpha=1)\n",
        "\n",
        "    with open(outfile, 'w') as writer:\n",
        "        outJson = {\n",
        "            f\"{networkShape}\": {\n",
        "                \"lambda\": regParam,\n",
        "                \"acc\": acc,\n",
        "                \"f1\": f1\n",
        "            }\n",
        "        }\n",
        "        writer.write(json.dumps(outJson))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Data Sets\n",
        "\n"
      ],
      "metadata": {
        "id": "WOw2WkmdP2YF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Shared Variables"
      ],
      "metadata": {
        "id": "7Yx2AivHQUVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set target directory for output files here\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/Colab Notebooks/cs589/data/output\"\n",
        "\n",
        "# Set network structures to use here\n",
        "STRUCTURES = [\n",
        "    [2],\n",
        "    [4],\n",
        "    [8],\n",
        "    [4, 4],\n",
        "    [8, 8, 8],\n",
        "    [16, 16, 16, 16]\n",
        "]\n",
        "\n",
        "# Test regularization parameters\n",
        "REG_PARAMS = [\n",
        "    0,\n",
        "    0.25,\n",
        "    0.5,\n",
        "    0.75,\n",
        "    1\n",
        "]"
      ],
      "metadata": {
        "id": "wYLHqIvrQWtP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process Wine Data"
      ],
      "metadata": {
        "id": "O2VITqv7QXgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(STRUCTURES)):\n",
        "    for regParam in REG_PARAMS:\n",
        "        # Set output file\n",
        "        wineOut = f\"{OUTPUT_DIR}/wine_S{i}_L{regParam}_data.json\"\n",
        "\n",
        "        # Conduct experiment\n",
        "        process_wine(STRUCTURES[i], regParam, wineOut)"
      ],
      "metadata": {
        "id": "CZJgIDAKP4S3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "bc3c049c-ee95-4228-aa59-a8b0b5f62d56"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structure: [13, 2, 3]\n",
            "Average Accuracy: 0.5672794117647059\n",
            "Average F1: 0.012698412698412698\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-4e14545d2b53>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Conduct experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprocess_wine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTRUCTURES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwineOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-44911bab1049>\u001b[0m in \u001b[0;36mprocess_wine\u001b[0;34m(networkShape, regParam, outfile)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Pass wine data set through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Will automatically one-hot encode class column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwineNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetworkShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-bc4e0b38f4c7>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(df, layerStructure, regParam, alpha, epsilon)\u001b[0m\n\u001b[1;32m     66\u001b[0m         )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Propagate each instance through network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2f1b6fe0d374>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, batchSize)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassify_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelledInstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2f1b6fe0d374>\u001b[0m in \u001b[0;36mbackpropagate\u001b[0;34m(self, batches)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;31m# Process the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;31m# Update start index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2f1b6fe0d374>\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(self, startIndex, endIndex)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mcurInstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoLabelTrainData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mactivations_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurInstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivations_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintOut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugFlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Compute delta values for output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2f1b6fe0d374>\u001b[0m in \u001b[0;36mpropagate_one\u001b[0;34m(self, instance, activations, printOut)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# Compute activation vector of current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mcurActivationVec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_activation_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Add bias term to current activation vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2f1b6fe0d374>\u001b[0m in \u001b[0;36mcompute_activation_vector\u001b[0;34m(self, weightedSums)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Compute output of sigmoid function and place it in activation vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mactivationVector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mactivationVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2f1b6fe0d374>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Definition for the sigmoid function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process House Data"
      ],
      "metadata": {
        "id": "vBIU1Gk3R_i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(STRUCTURES)):\n",
        "    for regParam in REG_PARAMS:\n",
        "        # Set output file\n",
        "        houseOut = f\"{OUTPUT_DIR}/house_S{i}_L{regParam}_data.json\"\n",
        "\n",
        "        # Conduct experiment\n",
        "        process_house(STRUCTURES[i], regParam, houseOut)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXV0340oSBJd",
        "outputId": "3388d1d4-e7bb-423d-f8e4-2f08efb90fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structure: [48, 2, 2]\n",
            "Average Accuracy: 0.8610275689223057\n",
            "Average F1: 0.08229186892510823\n",
            "Structure: [48, 2, 2]\n",
            "Average Accuracy: 0.8204260651629074\n",
            "Average F1: 0.08918489591951552\n",
            "Structure: [48, 2, 2]\n",
            "Average Accuracy: 0.8602756892230576\n",
            "Average F1: 0.03666666666666667\n",
            "Structure: [48, 2, 2]\n",
            "Average Accuracy: 0.8728070175438596\n",
            "Average F1: 0.08920454545454545\n",
            "Structure: [48, 2, 2]\n",
            "Average Accuracy: 0.8555137844611529\n",
            "Average F1: 0.09108097149154727\n",
            "Structure: [48, 4, 2]\n",
            "Average Accuracy: 0.8665413533834586\n",
            "Average F1: 0.07317879187856671\n",
            "Structure: [48, 4, 2]\n",
            "Average Accuracy: 0.9340852130325814\n",
            "Average F1: 0.09108097149154727\n",
            "Structure: [48, 4, 2]\n",
            "Average Accuracy: 0.9190476190476191\n",
            "Average F1: 0.1\n",
            "Structure: [48, 4, 2]\n",
            "Average Accuracy: 0.9328320802005013\n",
            "Average F1: 0.09478021978021978\n",
            "Structure: [48, 4, 2]\n",
            "Average Accuracy: 0.9204260651629073\n",
            "Average F1: 0.08942597234703369\n",
            "Structure: [48, 8, 2]\n",
            "Average Accuracy: 0.9203007518796994\n",
            "Average F1: 0.09640151515151515\n",
            "Structure: [48, 8, 2]\n",
            "Average Accuracy: 0.9250626566416041\n",
            "Average F1: 0.09640151515151515\n",
            "Structure: [48, 8, 2]\n",
            "Average Accuracy: 0.9268170426065163\n",
            "Average F1: 0.09824182603331276\n",
            "Structure: [48, 8, 2]\n",
            "Average Accuracy: 0.9293233082706767\n",
            "Average F1: 0.09109747244770013\n",
            "Structure: [48, 8, 2]\n",
            "Average Accuracy: 0.9275689223057645\n",
            "Average F1: 0.08920454545454545\n",
            "Structure: [48, 4, 4, 2]\n",
            "Average Accuracy: 0.843609022556391\n",
            "Average F1: 0.03666666666666667\n",
            "Structure: [48, 4, 4, 2]\n",
            "Average Accuracy: 0.8263157894736842\n",
            "Average F1: 0.09299301335422167\n",
            "Structure: [48, 4, 4, 2]\n",
            "Average Accuracy: 0.7721804511278197\n",
            "Average F1: 0.03666666666666667\n",
            "Structure: [48, 4, 4, 2]\n",
            "Average Accuracy: 0.7793233082706768\n",
            "Average F1: 0.09109747244770013\n",
            "Structure: [48, 4, 4, 2]\n",
            "Average Accuracy: 0.7561403508771929\n",
            "Average F1: 0.08918489591951552\n",
            "Structure: [48, 8, 8, 8, 2]\n",
            "Average Accuracy: 0.8197994987468672\n",
            "Average F1: 0.03666666666666667\n",
            "Structure: [48, 8, 8, 8, 2]\n",
            "Average Accuracy: 0.8358395989974937\n",
            "Average F1: 0.09283428226248733\n",
            "Structure: [48, 8, 8, 8, 2]\n",
            "Average Accuracy: 0.8822055137844613\n",
            "Average F1: 0.09640151515151515\n",
            "Structure: [48, 8, 8, 8, 2]\n",
            "Average Accuracy: 0.8602756892230579\n",
            "Average F1: 0.03666666666666667\n",
            "Structure: [48, 8, 8, 8, 2]\n",
            "Average Accuracy: 0.7083959899749372\n",
            "Average F1: 0.09640151515151515\n",
            "Structure: [48, 16, 16, 16, 16, 2]\n",
            "Average Accuracy: 0.8709273182957394\n",
            "Average F1: 0.09460069737792046\n",
            "Structure: [48, 16, 16, 16, 16, 2]\n",
            "Average Accuracy: 0.9401002506265664\n",
            "Average F1: 0.08823702830188682\n",
            "Structure: [48, 16, 16, 16, 16, 2]\n",
            "Average Accuracy: 0.9399749373433585\n",
            "Average F1: 0.09466139971789563\n",
            "Structure: [48, 16, 16, 16, 16, 2]\n",
            "Average Accuracy: 0.9364661654135338\n",
            "Average F1: 0.09109747244770013\n",
            "Structure: [48, 16, 16, 16, 16, 2]\n",
            "Average Accuracy: 0.887593984962406\n",
            "Average F1: 0.09460069737792046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Learning Curves"
      ],
      "metadata": {
        "id": "CA2lMkmDAk3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "House Votes Learning Curve"
      ],
      "metadata": {
        "id": "KXqEVLYJBHZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def house_votes_curve():\n",
        "    # Define network hyperparameters\n",
        "    idealShape = [48, 8, 2]\n",
        "    alpha = 1\n",
        "    regParam = 1\n",
        "    epsilon = 0.0001\n",
        "\n",
        "    # Load data\n",
        "    houseData = loadCSV(HOUSE_CSV, ',')\n",
        "\n",
        "    # Get one hot encoded version of data set\n",
        "    oneHotDf = pd.get_dummies(houseData)\n",
        "\n",
        "    # From the entire data set, determine its class labels and features\n",
        "    classLabels = {}\n",
        "    features = set()\n",
        "    index = 0\n",
        "    for col in oneHotDf:\n",
        "        if \"class\" in col:\n",
        "            classLabels[col] = index\n",
        "            index += 1\n",
        "        else:\n",
        "            features.add(col)\n",
        "    \n",
        "    # Generate stratified folds\n",
        "    dataFolds = generate_stratified_folds(oneHotDf, classLabels)\n",
        "\n",
        "    # Choose one set to be test set\n",
        "    testData = dataFolds[0]\n",
        "    testNoLabels = testData.loc[:, ~testData.columns.isin(classLabels)]\n",
        "\n",
        "    # Test combining different folds\n",
        "    numFolds = [2, 3, 4, 5, 6]\n",
        "    errors = {}\n",
        "    for num in numFolds:\n",
        "        # Generate training set based on number of folds\n",
        "        trainFolds = []\n",
        "        for j in range(1, num + 1):\n",
        "            trainFolds.append(dataFolds[j])\n",
        "        trainData = pd.concat(trainFolds)\n",
        "\n",
        "        # Create and train neural network\n",
        "        nn = NeuralNetwork(\n",
        "            idealShape, \n",
        "            trainData,\n",
        "            classLabels,\n",
        "            regParam=regParam,\n",
        "            alpha=alpha,\n",
        "            epsilon=epsilon\n",
        "        )\n",
        "\n",
        "        nn.train_network()\n",
        "\n",
        "        # Compute cost over all test instances\n",
        "        cost = nn.compute_error(testNoLabels)\n",
        "        errors[len(trainData)] = cost\n",
        "    \n",
        "    print(errors)\n",
        "\n",
        "    # Create plot\n",
        "    x_axis = []\n",
        "    y_axis = []\n",
        "    for size in errors:\n",
        "        x_axis.append(size)\n",
        "        y_axis.append(errors[size])\n",
        "    \n",
        "    plt.plot(x_axis, y_axis)\n",
        "    plt.title(\"Error on Test Data vs. Size of Training Set (House Votes)\")\n",
        "    plt.xlabel(\"Size of Training Set\")\n",
        "    plt.ylabel(\"Average Regularized Cost over Test Set\")\n",
        "    plt.show()\n",
        "\n",
        "def wine_curve():\n",
        "    # Define network hyperparameters\n",
        "    idealShape = [13, 8, 3]\n",
        "    alpha = 1\n",
        "    regParam = 0\n",
        "    epsilon = 0.0001\n",
        "\n",
        "    wineData = loadCSV(WINE_CSV, '\\t')\n",
        "    \n",
        "    # Set attribute value map\n",
        "    attrTypes = {}\n",
        "    for col in wineData.columns:\n",
        "        if col != \"class\":\n",
        "            attrTypes[col] = 'numerical'\n",
        "    \n",
        "    # Parse data types\n",
        "    wineData = parseTypes(wineData, attrTypes)\n",
        "    wineNoLabels = wineData.loc[:, wineData.columns!='class']\n",
        "    \n",
        "    # Normalize data set\n",
        "    wineNormal = (wineNoLabels - wineNoLabels.min()) / (wineNoLabels.max() - wineNoLabels.min())\n",
        "    wineNormal['class'] = wineData['class']\n",
        "\n",
        "    # One hot encode wine data\n",
        "    wineOneHot = pd.get_dummies(wineNormal)\n",
        "    classLabels = {'class_1': 0, 'class_2': 1, 'class_3': 2}\n",
        "\n",
        "    # Generate stratified folds\n",
        "    dataFolds = generate_stratified_folds(wineOneHot, classLabels)\n",
        "\n",
        "    # Choose one data set to be test set\n",
        "    testData = dataFolds[0]\n",
        "    testNoLabels = testData.loc[:, ~testData.columns.isin(classLabels)]\n",
        "\n",
        "    # Test combining different folds\n",
        "    numFolds = [2, 3, 4, 5, 6]\n",
        "    errors = {}\n",
        "    for num in numFolds:\n",
        "        # Generate training set based on number of folds\n",
        "        trainFolds = []\n",
        "        for j in range(1, num + 1):\n",
        "            trainFolds.append(dataFolds[j])\n",
        "        trainData = pd.concat(trainFolds)\n",
        "\n",
        "        # Create and train neural network\n",
        "        nn = NeuralNetwork(\n",
        "            idealShape, \n",
        "            trainData,\n",
        "            classLabels,\n",
        "            regParam=regParam,\n",
        "            alpha=alpha,\n",
        "            epsilon=epsilon\n",
        "        )\n",
        "\n",
        "        nn.train_network()\n",
        "\n",
        "        # Compute cost over all test instances\n",
        "        cost = nn.compute_error(testNoLabels)\n",
        "        errors[len(trainData)] = cost\n",
        "    \n",
        "    print(errors)\n",
        "\n",
        "    # Create plot\n",
        "    x_axis = []\n",
        "    y_axis = []\n",
        "    for size in errors:\n",
        "        x_axis.append(size)\n",
        "        y_axis.append(errors[size])\n",
        "    \n",
        "    plt.plot(x_axis, y_axis)\n",
        "    plt.title(\"Error on Test Data vs. Size of Training Set (Wine)\")\n",
        "    plt.xlabel(\"Size of Training Set\")\n",
        "    plt.ylabel(\"Average Regularized Cost over Test Set\")\n",
        "    plt.show()\n",
        "\n",
        "wine_curve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "KE4KVKkyBGld",
        "outputId": "2ce39a90-c076-4009-b591-a14ce3a962fb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
            "       'class_1', 'class_2', 'class_3'],\n",
            "      dtype='object')\n",
            "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
            "       'class_1', 'class_2', 'class_3'],\n",
            "      dtype='object')\n",
            "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
            "       'class_1', 'class_2', 'class_3'],\n",
            "      dtype='object')\n",
            "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
            "       'class_1', 'class_2', 'class_3'],\n",
            "      dtype='object')\n",
            "Index(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
            "       'class_1', 'class_2', 'class_3'],\n",
            "      dtype='object')\n",
            "{32: 0.9178477567266337, 48: 0.33867385011107953, 64: 0.21980498919151453, 80: 0.10703802286144327, 96: 0.08640805997748222}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCaC54/IZlmvgLuqWfEm3X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}