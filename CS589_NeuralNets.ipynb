{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewu2023/CS589-HW4/blob/main/CS589_NeuralNets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg570F-XxICR"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEWGG2M_xNfo",
        "outputId": "cb4439bc-22ab-40f0-983f-b28473157e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B-JBg83M1ok"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WsRlxN3fLmfw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "\n",
        "# For reading/writing to files\n",
        "import json\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOW3NjBRNpsU"
      },
      "source": [
        "# Define Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PlC7io6JNYw8"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self, networkShape, trainData: pd.DataFrame, classLabels, weights=None, regParam=0, alpha=0.01, epsilon=0.01, debugFlag=False):\n",
        "        \"\"\"\n",
        "        Constructor for the neural network class.\n",
        "        \n",
        "        networkShape: A list of integers that contains the number of neurons to use in each layer\n",
        "\n",
        "        trainData: The data set that will be used to train the model\n",
        "\n",
        "        weights: A list of weight matrices for each hidden layer. If initialized to None, the constructor will assign random weights\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Process training data\n",
        "        \"\"\"\n",
        "        self.trainData = trainData\n",
        "\n",
        "        \n",
        "        # Get a copy of the training data without the labels\n",
        "        self.noLabelTrainData = trainData.loc[:, ~trainData.columns.isin(classLabels)]\n",
        "        self.classLabels = classLabels\n",
        "\n",
        "        # Encode class vectors\n",
        "        self.classVectors = {}\n",
        "        for i in range(len(trainData)):\n",
        "            # Get current row from training data\n",
        "            row = trainData.iloc[i]\n",
        "\n",
        "            # Iterate over all classes and assign values\n",
        "            classVector = {}\n",
        "            for label in classLabels:\n",
        "                expVal = row[label]\n",
        "                classVector[label] = [expVal]\n",
        "\n",
        "            # Convert class vector to numpy array\n",
        "            classVecDf = pd.DataFrame(classVector)\n",
        "\n",
        "            # Append class vector to dictionary of vectors\n",
        "            # Implementation uses column vectors, so we take transpose here\n",
        "            self.classVectors[i] = (classVecDf.to_numpy()).T\n",
        "\n",
        "        self.networkShape = networkShape\n",
        "\n",
        "        # Set the value of the regularization parameter\n",
        "        self.regParam = regParam\n",
        "\n",
        "        # Set the step size for gradient descent\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Set value of epsilon for stopping condition\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        # Set debug flag to show output of intermediate computations\n",
        "        self.debugFlag = debugFlag\n",
        "\n",
        "        # Instance variable storing weight matrices\n",
        "        self.layers = []\n",
        "        \n",
        "        # Initialize layers\n",
        "        for i in range(len(networkShape) - 1):\n",
        "            # Get the number of neurons in the current and next layers\n",
        "            numCurLayer = networkShape[i] + 1 # Account for neurons + bias term in current layer\n",
        "            numNextLayer = networkShape[i + 1]\n",
        "\n",
        "            # Initialize matrix for the current layer\n",
        "            # Number of rows = number of neurons in layer i + 1\n",
        "            # Number of columns = number of neurons in layer i\n",
        "            layerMatrix = np.zeros(shape=(numNextLayer, numCurLayer))\n",
        "            if weights:\n",
        "                layerMatrix = weights[i]\n",
        "            else:\n",
        "                self._init_matrix(layerMatrix)\n",
        "            \n",
        "            # Append current layer to the list of layers\n",
        "            self.layers.append(layerMatrix)\n",
        "        \n",
        "    def _init_matrix(self, matrix: np.ndarray):\n",
        "        rows, cols = matrix.shape\n",
        "        for i in range(rows):\n",
        "            for j in range(cols):\n",
        "                matrix[i, j] = norm.rvs()\n",
        "    \n",
        "    # Definition for the sigmoid function\n",
        "    def sigmoid(self, x):\n",
        "        return (1 / (1 + np.exp(-x)))\n",
        "    \n",
        "    # Compute activation vector\n",
        "    def compute_activation_vector(self, weightedSums: np.ndarray):\n",
        "        numRows, numCols = weightedSums.shape\n",
        "        activationVector = np.zeros(shape=(numRows, numCols))\n",
        "\n",
        "        for i in range(numRows):\n",
        "            # Get weighted sum from i-th row\n",
        "            x = weightedSums[i, 0]\n",
        "\n",
        "            # Compute output of sigmoid function and place it in activation vector\n",
        "            activationVector[i, 0] = self.sigmoid(x)\n",
        "        \n",
        "        return activationVector\n",
        "    \n",
        "    # Method for propagating forward one instance\n",
        "    def propagate_one(self, instance, activations=None, printOut=False):\n",
        "        # Add a bias term to the instance\n",
        "        instanceAsNP = instance.to_numpy()\n",
        "        instanceVector = np.concatenate(([1], instanceAsNP))\n",
        "        \n",
        "        # Make instance vector a column vector\n",
        "        instanceVector = np.atleast_2d(instanceVector).T\n",
        "        \n",
        "        # Iterate over each layer and compute activations for each neuron\n",
        "        prevActivation = instanceVector # Keep track of the activation vector for previous layer\n",
        "\n",
        "        if activations != None: # If activations is not None, append current activation\n",
        "            activations.append(prevActivation)\n",
        "\n",
        "        # If the debug flag was set, print out the first instance vector\n",
        "        if printOut:\n",
        "            print(f\"Value of a0:\\n{prevActivation}\\n\")\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            # Get current weight matrix\n",
        "            curTheta = self.layers[i]\n",
        "\n",
        "            # Compute weighted sum vector (z-matrix): Theta^{l=i-1} * a^{l=i-1}\n",
        "            z = np.matmul(curTheta, prevActivation)\n",
        "\n",
        "            # Compute activation vector of current layer\n",
        "            curActivationVec = self.compute_activation_vector(z)\n",
        "            \n",
        "            # Add bias term to current activation vector\n",
        "            curActivationVec = np.concatenate(([[1]], curActivationVec)) # Prepend 1 to vector\n",
        "\n",
        "            # Update previous activation vector\n",
        "            prevActivation = curActivationVec\n",
        "\n",
        "            # Append current activation to list\n",
        "            if activations != None:\n",
        "                activations.append(curActivationVec)\n",
        "\n",
        "            # Print results of computation at this step if debug flag is on\n",
        "            if printOut:\n",
        "                print(f\"Value of z{i + 1}:\\n{z}\")\n",
        "                print(f\"Value of a{i + 1}:\\n{curActivationVec}\\n\")\n",
        "        \n",
        "        # Compute activation at the final layer\n",
        "        lastTheta = self.layers[len(self.layers) - 1]\n",
        "        lastZMat = np.matmul(lastTheta, prevActivation)\n",
        "        outputVector = self.compute_activation_vector(lastZMat)\n",
        "\n",
        "        # If the debug flag was set, print results of this final computation\n",
        "        if printOut:\n",
        "            print(f\"Value of z{len(self.layers)}:\\n{lastZMat}\")\n",
        "            print(f\"Value of a{len(self.layers)}:\\n{outputVector}\\n\")\n",
        "\n",
        "        if activations != None:\n",
        "            activations.append(outputVector)\n",
        "\n",
        "        # Return as a vector in the event there are multiple outputs\n",
        "        return outputVector\n",
        "\n",
        "    # Compute error for an individual output of the neural network\n",
        "    def compute_one_instance_err(self, expVal, predVal):\n",
        "        return -expVal * np.log(predVal) - (1 - expVal) * np.log(1 - predVal)\n",
        "\n",
        "    # Helper method for computing regularized error\n",
        "    def compute_error(self, printOut=False):\n",
        "        # Keep track of total error across all training instances\n",
        "        totalErr = 0\n",
        "\n",
        "        # Iterate over all training instances\n",
        "        for i in range(len(self.noLabelTrainData)):\n",
        "            # Get current instance and perform forward propagation on it\n",
        "            curInstance = self.noLabelTrainData.iloc[i]\n",
        "            predVector = self.propagate_one(curInstance, printOut=False) # Will be a vector\n",
        "\n",
        "            # Get the expected values vector\n",
        "            expVector = self.classVectors[i]\n",
        "\n",
        "            # Compute error vector\n",
        "            vectorizedErrorFunc = np.vectorize(self.compute_one_instance_err)\n",
        "            errVector = vectorizedErrorFunc(expVector, predVector)\n",
        "\n",
        "            if printOut:\n",
        "                print(f\"Cost associated with Instance {i}: {np.sum(errVector)}\\n\")\n",
        "            # Sum all elements of error vector, then add it to total error\n",
        "            totalErr += np.sum(errVector)\n",
        "        \n",
        "        # Compute average error\n",
        "        avgErr = totalErr / len(self.trainData)\n",
        "\n",
        "        \"\"\" Compute the squared sum of all weights in the network \"\"\"\n",
        "        weightSqSum = 0\n",
        "        for weightMatrix in self.layers:\n",
        "            # Square all of the weights\n",
        "            squaredMatrix = np.multiply(weightMatrix, weightMatrix)\n",
        "\n",
        "            # Drop bias terms from squared matrix\n",
        "            rows, cols = squaredMatrix.shape\n",
        "            zeroColumn = np.zeros(rows)\n",
        "            squaredMatrix[:, 0] = zeroColumn\n",
        "\n",
        "            # Add all columns, then add each column's total to get the total sum for this matrix\n",
        "            colSums = np.sum(squaredMatrix, axis=0)\n",
        "            matrixTotal = np.sum(colSums)\n",
        "\n",
        "            # Add matrix total to sum of the weights squared\n",
        "            weightSqSum += matrixTotal\n",
        "        \n",
        "        # Regularize error\n",
        "        weightSqSum *= (self.regParam / (2 * len(self.trainData)))\n",
        "\n",
        "        # Return error + regularization term\n",
        "        return avgErr + weightSqSum\n",
        "    \n",
        "    def backpropagate(self):\n",
        "        # Determine current error across entire data set \n",
        "        prevErr = self.compute_error(printOut=False)\n",
        "        converged = False\n",
        "        while not converged: \n",
        "            # Initialize gradients for each layer\n",
        "            # Accumulate the gradients in this list\n",
        "            gradients = []\n",
        "            for layer in self.layers:\n",
        "                # Get the shape of each layer\n",
        "                rows, cols = layer.shape\n",
        "                gradients.append(np.zeros(shape=(rows,cols)))\n",
        "\n",
        "\n",
        "            # Iterate over all instances in the training data\n",
        "            for i in range(len(self.noLabelTrainData)):\n",
        "                print(f\"--- Propagating Instance {i} ---\\n\")\n",
        "\n",
        "                # Propagate current instance through the network\n",
        "                curInstance = self.noLabelTrainData.iloc[i]\n",
        "                activations_i = []\n",
        "                self.propagate_one(curInstance, activations=activations_i, printOut=self.debugFlag)\n",
        "\n",
        "                # Compute delta values for output layer\n",
        "                outputVector = activations_i[len(activations_i) - 1]\n",
        "                if self.debugFlag:\n",
        "                    print(f\"Instance {i} Activation: {outputVector.T}\\n\")\n",
        "\n",
        "                expectedVector = self.classVectors[i]\n",
        "\n",
        "                delta_vectors = []\n",
        "                delta_vectors.append(outputVector - expectedVector)\n",
        "\n",
        "                # Iterate over each layer and compute delta values\n",
        "                for k in range(len(self.layers) - 1, 0, -1):\n",
        "                    # Get current weight matrix\n",
        "                    weightMatrix = self.layers[k]\n",
        "                    delta_next = delta_vectors[0]\n",
        "\n",
        "                    # Compute delta values for nodes in current layer\n",
        "                    a = np.matmul(weightMatrix.T, delta_next)\n",
        "                    b = np.multiply(a, activations_i[k])\n",
        "                    delta_k = np.multiply(b, (1 - activations_i[k]))\n",
        "\n",
        "                    # Remove bias term from delta_k\n",
        "                    delta_k = np.delete(delta_k, 0, 0)\n",
        "\n",
        "                    # Append to delta vectors\n",
        "                    delta_vectors.insert(0, delta_k)\n",
        "\n",
        "                \n",
        "                # Accumulate the gradients for each layer\n",
        "                if self.debugFlag:\n",
        "                    print(f\"Instance {i} Deltas:\\n\")\n",
        "                    for deltaIndex in range(len(delta_vectors)):\n",
        "                        print(f\"Deltas for Layer {deltaIndex}:\\n{delta_vectors[deltaIndex]}\\n\")\n",
        "                \n",
        "                for j in range(len(self.layers) - 1, -1, -1):\n",
        "                    curGradLayer = gradients[j]\n",
        "\n",
        "                    # Compute gradients of this instance for current layer\n",
        "                    gradMatrix = np.matmul(delta_vectors[j], activations_i[j].T)\n",
        "                    if self.debugFlag:\n",
        "                        print(f\"Gradients of Theta{j} on instance {i}:\\n{gradMatrix}\\n\")\n",
        "\n",
        "                    # Accumulate the gradients\n",
        "                    curGradLayer = curGradLayer + gradMatrix\n",
        "                    gradients[j] = curGradLayer\n",
        "\n",
        "            # Iterate over each layer and compute gradient + regularization factor\n",
        "            for i in range(len(self.layers) - 1, -1, -1):\n",
        "                regFactor = np.multiply(self.regParam, self.layers[i])\n",
        "                # Set first col of regFactor to 0s\n",
        "                rows, cols = regFactor.shape\n",
        "                regFactor[:,0] = np.zeros(rows)\n",
        "\n",
        "                curGradLayer = gradients[i]\n",
        "\n",
        "                curGradLayer = (1 / len(self.trainData)) * (curGradLayer + regFactor)\n",
        "                gradients[i] = curGradLayer\n",
        "\n",
        "            # Print error cost and final gradients\n",
        "            if self.debugFlag:\n",
        "                print(\"----------\")\n",
        "                print(f\"Final (regularized) cost J based on Entire Set: {self.compute_error(printOut=True)}\")\n",
        "                print(f\"Final Average, Regularized Gradients:\\n\")\n",
        "                for gradIndex in range(len(gradients)):\n",
        "                    print(f\"Final Regularized gradients of Theta{gradIndex}:\\n{gradients[gradIndex]}\\n\")\n",
        "\n",
        "            # Update weights according to gradients\n",
        "            for i in range(len(self.layers) - 1, -1, -1):\n",
        "                self.layers[i] = self.layers[i] - self.alpha * gradients[i]\n",
        "            \n",
        "            # Compute current error and check for stopping condition\n",
        "            curErr = self.compute_error(printOut=False)\n",
        "            if np.absolute(prevErr - curErr) <= self.epsilon:\n",
        "                # If the difference in error is equal to or smaller than\n",
        "                # the given value of epsilon, consider the network as converged\n",
        "                converged = True\n",
        "                continue\n",
        "            \n",
        "            prevErr = curErr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxzyGtabHfub"
      },
      "source": [
        "Test Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8_y6PpYnHiGr"
      },
      "outputs": [],
      "source": [
        "def backprop_example_1():\n",
        "    d = {\n",
        "        'x': [0.13000, 0.42000], \n",
        "        'class': [0.90000, 0.23000]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data=d)\n",
        "    df_noLabels = df.loc[:, df.columns!='class']\n",
        "\n",
        "    networkShape = [1, 2, 1]\n",
        "    weights = [\n",
        "        np.array(\n",
        "            [[0.40000, 0.10000],\n",
        "            [0.30000, 0.20000]],\n",
        "        ),\n",
        "\n",
        "        np.array([[0.70000, 0.50000, 0.60000]])\n",
        "    ]\n",
        "\n",
        "    classLabels = ['class']\n",
        "    network = NeuralNetwork(networkShape, trainData=df, classLabels=classLabels, weights=weights, debugFlag=True)\n",
        "    network.backpropagate()\n",
        "\n",
        "def backprop_example_2():\n",
        "    # Pre-process data\n",
        "    d = {\n",
        "        \"x1\": [0.32000, 0.83000],\n",
        "        \"x2\": [0.68000, 0.02000],\n",
        "        \"y1\": [0.75000, 0.75000],\n",
        "        \"y2\": [0.98000, 0.28000]\n",
        "    }\n",
        "\n",
        "    classLabels = [\"y1\", \"y2\"]\n",
        "\n",
        "    df = pd.DataFrame(d)\n",
        "    df_noLabels = df.loc[:, ~df.columns.isin(classLabels)]\n",
        "    \n",
        "    # Initialize network\n",
        "    networkShape = [2, 4, 3, 2]\n",
        "    weights = [\n",
        "        np.array([\n",
        "            [0.42000, 0.15000, 0.40000],\n",
        "            [0.72000, 0.10000, 0.54000],\n",
        "            [0.01000, 0.19000, 0.42000],\n",
        "            [0.30000, 0.35000, 0.68000]\n",
        "        ]),\n",
        "\n",
        "        np.array([\n",
        "            [0.21000, 0.67000, 0.14000, 0.96000, 0.87000],\n",
        "            [0.87000, 0.42000, 0.20000, 0.32000, 0.89000],\n",
        "            [0.03000, 0.56000, 0.80000, 0.69000, 0.09000]\n",
        "        ]),\n",
        "\n",
        "        np.array([\n",
        "            [0.04000,  0.87000,  0.42000,  0.53000],\n",
        "            [0.17000,  0.10000,  0.95000,  0.69000]\n",
        "        ])\n",
        "    ]\n",
        "\n",
        "    network = NeuralNetwork(\n",
        "        networkShape, \n",
        "        df, \n",
        "        classLabels=classLabels, \n",
        "        weights=weights, \n",
        "        regParam=0.25, \n",
        "        debugFlag=True\n",
        "    )\n",
        "\n",
        "    network.backpropagate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Utilities"
      ],
      "metadata": {
        "id": "uqkfs67QkGIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CSV Helper Function"
      ],
      "metadata": {
        "id": "UMAkNILplX5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular expressions for integers and floats\n",
        "FLOAT_REGEX = \"[-+]?[0-9]+\\.[0-9]+\"\n",
        "INTEGER_REGEX = \"[-+]?[0-9]+\"\n",
        "def loadCSV(filename, delimeter):\n",
        "    with open (filename) as csvfile:\n",
        "        reader = csv.DictReader(csvfile, delimiter=delimeter)\n",
        "        i = 0\n",
        "        data_table = []\n",
        "        for row in reader:\n",
        "            # Create a new row in the data table\n",
        "            data_table.append({})\n",
        "            cur_table_row = data_table[i]\n",
        "\n",
        "            # Copy over each column volume into the new row\n",
        "            for col in row:\n",
        "                col_lower = col.lower()\n",
        "                if \"class\" in col_lower:\n",
        "                    cur_table_row['class'] = row[col]\n",
        "                else:\n",
        "                    cur_table_row[col_lower] = row[col]\n",
        "            i += 1\n",
        "        \n",
        "        df = pd.DataFrame(data_table)\n",
        "        return df"
      ],
      "metadata": {
        "id": "v8PaCttDkHcD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign Data Types to Attributes"
      ],
      "metadata": {
        "id": "_fVH_M1ptWre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempts to assign data types to each column and value, depending on format\n",
        "def parseTypes(df: pd.DataFrame, attrTypes=None):\n",
        "    data_table = []\n",
        "    for i in range(len(df)):\n",
        "        # Get current row in dataframe\n",
        "        row = df.iloc[i]\n",
        "\n",
        "        # Create new row in the table\n",
        "        data_table.append({})\n",
        "        cur_table_row = data_table[i]\n",
        "\n",
        "        # Copy over each column volume into the new row\n",
        "        for col in df:\n",
        "            col_lower = col.lower()\n",
        "            if 'class' in col_lower:\n",
        "                # Copy value of class to current row in table\n",
        "                cur_table_row['class'] = row[col]\n",
        "            else:\n",
        "                cur_value = row[col]\n",
        "                colType = None\n",
        "                # Check if a type for the current attribute was specified\n",
        "                if attrTypes:\n",
        "                    if col in attrTypes:\n",
        "                        colType = attrTypes[col]\n",
        "                \n",
        "                if colType == 'categorical' or colType == None:\n",
        "                    # Store value as a string\n",
        "                    cur_table_row[col_lower] = cur_value\n",
        "                else:\n",
        "                    if re.fullmatch(FLOAT_REGEX, cur_value):\n",
        "                        # Store this value as a float\n",
        "                        cur_table_row[col_lower] = float(cur_value)\n",
        "                    else:\n",
        "                        # Store this value as an integer\n",
        "                        cur_table_row[col_lower] = int(cur_value)\n",
        "    \n",
        "    # Return the data frame with the formatted values\n",
        "    formattedDf = pd.DataFrame(data_table)\n",
        "    return formattedDf"
      ],
      "metadata": {
        "id": "4sjsJksXtag-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JObkuUYH0ATB"
      },
      "source": [
        "# Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wQR5HQY0BkY",
        "outputId": "1e287069-6679-4353-814c-1d5b5f7bca60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 6]\n",
            "[3 7]\n",
            "Sum of all elements in matrix: 10\n",
            "b-vector elements squared:\n",
            "[[ 9]\n",
            " [49]]\n",
            "[[ 6]\n",
            " [14]]\n"
          ]
        }
      ],
      "source": [
        "# target_dir = \"/content/drive/My Drive/\"\n",
        "# filename = \"blarg.json\"\n",
        "# fileRoute = f\"{target_dir}/{filename}\"\n",
        "\n",
        "# with open(fileRoute, 'w') as outfile:\n",
        "#     some_data = {\n",
        "#         \"a1\": [[1, 2], [3, 4]],\n",
        "#         \"b1\": [[5, 6], [7, 8]]\n",
        "#     }\n",
        "\n",
        "#     outfile.write(json.dumps(some_data))\n",
        "\n",
        "# Compute error for an individual output of the neural network\n",
        "def compute_one_instance_err(expVal, predVal):\n",
        "    return -expVal * np.log(predVal) - (1 - expVal) * np.log(1 - predVal)\n",
        "\n",
        "def multiply(a, b):\n",
        "    return a * b\n",
        "\n",
        "\n",
        "vectorFunction = np.vectorize(multiply)\n",
        "a = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "colSum = np.sum(a, axis=0)\n",
        "rowSum = np.sum(a, axis=1)\n",
        "\n",
        "print(colSum)\n",
        "print(rowSum)\n",
        "print(f\"Sum of all elements in matrix: {np.sum(colSum)}\")\n",
        "\n",
        "b = np.array([\n",
        "    [3],\n",
        "    [7]\n",
        "])\n",
        "\n",
        "print(f\"b-vector elements squared:\\n{np.multiply(b, b)}\")\n",
        "# print(f\"b-vector - b-vector: {b - b}\")\n",
        "print(f\"{2 * b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Open File in Google Drive"
      ],
      "metadata": {
        "id": "o0NocjJJlrjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_dir = \"/content/drive/My Drive/Colab Notebooks/data\"\n",
        "wineCSV = f\"{target_dir}/hw3_wine.csv\"\n",
        "houseCSV = f\"{target_dir}/hw3_house_votes_84.csv\"\n",
        "\n",
        "# wine_data = loadCSV(wineCSV, '\\t')\n",
        "# print(pd.get_dummies(wine_data))\n",
        "\n",
        "house_data = loadCSV(houseCSV, ',')\n",
        "attrTypes = {'water-project-cost-sharing': 'numerical'}\n",
        "house_data = parseTypes(house_data, attrTypes=attrTypes)\n",
        "\n",
        "print(pd.get_dummies(house_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw65JiwyltSs",
        "outputId": "ea21435f-7084-4397-f9cd-dd0f8f690871"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     water-project-cost-sharing  ﻿#handicapped-infants_0  \\\n",
            "0                             2                        0   \n",
            "1                             2                        0   \n",
            "2                             2                        1   \n",
            "3                             2                        0   \n",
            "4                             2                        0   \n",
            "..                          ...                      ...   \n",
            "430                           1                        0   \n",
            "431                           1                        0   \n",
            "432                           0                        0   \n",
            "433                           1                        0   \n",
            "434                           2                        0   \n",
            "\n",
            "     ﻿#handicapped-infants_1  ﻿#handicapped-infants_2  \\\n",
            "0                          1                        0   \n",
            "1                          1                        0   \n",
            "2                          0                        0   \n",
            "3                          1                        0   \n",
            "4                          0                        1   \n",
            "..                       ...                      ...   \n",
            "430                        1                        0   \n",
            "431                        1                        0   \n",
            "432                        1                        0   \n",
            "433                        1                        0   \n",
            "434                        1                        0   \n",
            "\n",
            "     adoption-of-the-budget-resolution_0  adoption-of-the-budget-resolution_1  \\\n",
            "0                                      0                                    1   \n",
            "1                                      0                                    1   \n",
            "2                                      0                                    0   \n",
            "3                                      0                                    0   \n",
            "4                                      0                                    0   \n",
            "..                                   ...                                  ...   \n",
            "430                                    0                                    0   \n",
            "431                                    0                                    0   \n",
            "432                                    0                                    1   \n",
            "433                                    0                                    1   \n",
            "434                                    0                                    1   \n",
            "\n",
            "     adoption-of-the-budget-resolution_2  physician-fee-freeze_0  \\\n",
            "0                                      0                       0   \n",
            "1                                      0                       0   \n",
            "2                                      1                       1   \n",
            "3                                      1                       0   \n",
            "4                                      1                       0   \n",
            "..                                   ...                     ...   \n",
            "430                                    1                       0   \n",
            "431                                    1                       0   \n",
            "432                                    0                       0   \n",
            "433                                    0                       0   \n",
            "434                                    0                       0   \n",
            "\n",
            "     physician-fee-freeze_1  physician-fee-freeze_2  ...  crime_1  crime_2  \\\n",
            "0                         0                       1  ...        0        1   \n",
            "1                         0                       1  ...        0        1   \n",
            "2                         0                       0  ...        0        1   \n",
            "3                         1                       0  ...        1        0   \n",
            "4                         1                       0  ...        0        1   \n",
            "..                      ...                     ...  ...      ...      ...   \n",
            "430                       0                       1  ...        0        1   \n",
            "431                       1                       0  ...        1        0   \n",
            "432                       0                       1  ...        0        1   \n",
            "433                       0                       1  ...        0        1   \n",
            "434                       0                       1  ...        0        1   \n",
            "\n",
            "     duty-free-exports_0  duty-free-exports_1  duty-free-exports_2  \\\n",
            "0                      0                    1                    0   \n",
            "1                      0                    1                    0   \n",
            "2                      0                    1                    0   \n",
            "3                      0                    1                    0   \n",
            "4                      0                    0                    1   \n",
            "..                   ...                  ...                  ...   \n",
            "430                    0                    1                    0   \n",
            "431                    0                    1                    0   \n",
            "432                    0                    1                    0   \n",
            "433                    0                    1                    0   \n",
            "434                    1                    0                    0   \n",
            "\n",
            "     export-administration-act-south-africa_0  \\\n",
            "0                                           0   \n",
            "1                                           1   \n",
            "2                                           0   \n",
            "3                                           0   \n",
            "4                                           0   \n",
            "..                                        ...   \n",
            "430                                         0   \n",
            "431                                         0   \n",
            "432                                         0   \n",
            "433                                         0   \n",
            "434                                         0   \n",
            "\n",
            "     export-administration-act-south-africa_1  \\\n",
            "0                                           0   \n",
            "1                                           0   \n",
            "2                                           1   \n",
            "3                                           0   \n",
            "4                                           0   \n",
            "..                                        ...   \n",
            "430                                         0   \n",
            "431                                         0   \n",
            "432                                         0   \n",
            "433                                         0   \n",
            "434                                         1   \n",
            "\n",
            "     export-administration-act-south-africa_2  class_0  class_1  \n",
            "0                                           1        0        1  \n",
            "1                                           0        0        1  \n",
            "2                                           0        1        0  \n",
            "3                                           1        1        0  \n",
            "4                                           1        1        0  \n",
            "..                                        ...      ...      ...  \n",
            "430                                         1        0        1  \n",
            "431                                         1        1        0  \n",
            "432                                         1        0        1  \n",
            "433                                         1        0        1  \n",
            "434                                         0        0        1  \n",
            "\n",
            "[435 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Pandas Dummies"
      ],
      "metadata": {
        "id": "VJruN2ffcmiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"temperature\": [\"hot\", \"cool\", \"hot\"],\n",
        "    \"weather\": [\"sunny\", \"overcast\", \"sunny\"],\n",
        "    \"humidity\": [\"high\", \"normal\", \"high\"],\n",
        "    \"class\": [\"no\", \"yes\", \"no\"]\n",
        "}\n",
        "\n",
        "tennisDf = pd.DataFrame(data)\n",
        "encodedDf = pd.get_dummies(tennisDf)\n",
        "for i in range(len(encodedDf)):\n",
        "    print(f\"{encodedDf.iloc[i]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CylZyQ3cn4n",
        "outputId": "e52f385b-0ed8-4b01-d566-b15ad2d1fb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temperature_cool    0\n",
            "temperature_hot     1\n",
            "weather_overcast    0\n",
            "weather_sunny       1\n",
            "humidity_high       1\n",
            "humidity_normal     0\n",
            "class_no            1\n",
            "class_yes           0\n",
            "Name: 0, dtype: uint8\n",
            "\n",
            "temperature_cool    1\n",
            "temperature_hot     0\n",
            "weather_overcast    1\n",
            "weather_sunny       0\n",
            "humidity_high       0\n",
            "humidity_normal     1\n",
            "class_no            0\n",
            "class_yes           1\n",
            "Name: 1, dtype: uint8\n",
            "\n",
            "temperature_cool    0\n",
            "temperature_hot     1\n",
            "weather_overcast    0\n",
            "weather_sunny       1\n",
            "humidity_high       1\n",
            "humidity_normal     0\n",
            "class_no            1\n",
            "class_yes           0\n",
            "Name: 2, dtype: uint8\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkchMEAGfwVoYcGHUMKMlh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}